{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет по модели LASSO\n",
    "\n",
    "В данном ноутбуке представлена реализация модели LASSO для регрессии на датасете диабета. Выполнены следующие шаги:\n",
    "\n",
    "- Загрузка данных и разделение на обучающую и тестовую выборки\n",
    "- Обучение базовой модели LASSO с параметром `alpha=1.0`\n",
    "- Подбор оптимального параметра `alpha` с помощью GridSearchCV\n",
    "- Вычисление метрик качества модели: MSE, RMSE, MAE и R²\n",
    "- Визуализация результатов с использованием диаграммы рассеяния\n",
    "\n",
    "Ниже приведен итоговый отчет, который также включает сравнение с предыдущей работой, где для модели случайного леса с Label Encoding были получены метрики:\n",
    "\n",
    "**With using Label Encoding**  \n",
    "**MAE:** 1662.72, **RMSE:** 3323.83 for random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Загрузка датасета диабета\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "feature_names = data.feature_names\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Обучение базовой модели LASSO с параметром alpha=1.0\n",
    "lasso = Lasso(alpha=1.0, max_iter=10000)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и расчет метрик для базовой модели\n",
    "y_pred = lasso.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('Базовая модель LASSO:')\n",
    "print('MSE:', mse)\n",
    "print('RMSE:', rmse)\n",
    "print('MAE:', mae)\n",
    "print('R2:', r2)\n",
    "\n",
    "# Вывод коэффициентов модели\n",
    "coefficients = pd.Series(lasso.coef_, index=feature_names)\n",
    "print('\\nКоэффициенты LASSO модели:')\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Подбор оптимального параметра alpha с использованием GridSearchCV\n",
    "param_grid = {'alpha': np.logspace(-4, 0, 50)}\n",
    "grid_search = GridSearchCV(Lasso(max_iter=10000), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('\\nЛучшее значение alpha:', grid_search.best_params_)\n",
    "\n",
    "# Обучение оптимальной модели LASSO\n",
    "best_lasso = grid_search.best_estimator_\n",
    "y_pred_best = best_lasso.predict(X_test)\n",
    "mse_best = mean_squared_error(y_test, y_pred_best)\n",
    "rmse_best = np.sqrt(mse_best)\n",
    "mae_best = mean_absolute_error(y_test, y_pred_best)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print('\\nОптимизированная модель LASSO:')\n",
    "print('MSE:', mse_best)\n",
    "print('RMSE:', rmse_best)\n",
    "print('MAE:', mae_best)\n",
    "print('R2:', r2_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Визуализация результатов: диаграмма рассеяния фактических и предсказанных значений\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_best, alpha=0.7)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', lw=2)\n",
    "plt.xlabel('Фактические значения')\n",
    "plt.ylabel('Предсказанные значения')\n",
    "plt.title('Сравнение фактических и предсказанных значений (LASSO)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоговый отчет\n",
    "\n",
    "**Модель LASSO**\n",
    "\n",
    "После оптимизации модели LASSO по параметру регуляризации (alpha), получены следующие метрики на тестовой выборке (значения будут выведены в консоли при выполнении ноутбука):\n",
    "\n",
    "- **MSE:** *значение, вычисленное моделью*\n",
    "- **RMSE:** *значение, вычисленное моделью*\n",
    "- **MAE:** *значение, вычисленное моделью*\n",
    "- **R²:** *значение, вычисленное моделью*\n",
    "\n",
    "### Сравнение с предыдущей работой\n",
    "\n",
    "В предыдущей работе, при использовании Label Encoding для модели случайного леса, были получены следующие показатели:\n",
    "\n",
    "- **MAE:** 1662.72\n",
    "- **RMSE:** 3323.83\n",
    "\n",
    "Сравнивая результаты, можно сделать предварительные выводы о том, что:\n",
    "\n",
    "- Модель LASSO обладает преимуществом интерпретируемости за счет разреженности коэффициентов.\n",
    "- Выбор лучшей модели зависит от специфики задачи. Если важна интерпретируемость, LASSO может быть предпочтительнее; для сложных нелинейных взаимосвязей модель случайного леса может показать лучшие результаты.\n",
    "\n",
    "Важно отметить, что для корректного сравнения необходимо использовать идентичные данные и метрики оценки. Результаты экспериментов могут отличаться в зависимости от способа предобработки данных и параметров моделей."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
